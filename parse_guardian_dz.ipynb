{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "argv": [
        "python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "env": null,
      "interrupt_mode": "signal",
      "language": "python",
      "metadata": null,
      "name": "python3"
    },
    "name": "Untitled.ipynb",
    "colab": {
      "name": "parse_guardian_dz.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nstsj/python_for_CL/blob/master/parse_guardian_dz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ein.tags": "worksheet-0",
        "id": "cmjunHewA0wj",
        "colab_type": "text"
      },
      "source": [
        "Exercise: find all news written today on  and parse the content of https://www.theguardian.com/international each of them into a .txt file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URe3NPE0WNar",
        "colab_type": "text"
      },
      "source": [
        "стратегия работы:\n",
        "\n",
        "1. используйте код из тетрадки с пары или из этой (здесь то же самое, но в функциях), чтобы получить лист всех ссылок с главной страницы новостного сайта за определенный день (например, за сегодня)\n",
        "\n",
        "2. Из листа ссылок сделайте лист со ссылками только на новости (ссылки на катеогрии и другие разделы сайта не нужны)\n",
        "\n",
        "3. для каждой ссылки на новость в листе ссылок:\n",
        "    3.1. пройдите по ссылке\n",
        "    3.2. из этой веб-странички вытащите текст новости + ее заголовок\n",
        "    3.3. запишите в отдельный .txt файл\n",
        "\n",
        "4. сохраните файлы в папку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "wyX5gdEgA0wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import datetime as dt\n",
        "import re\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "6bTjw95CA0wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parsing_pipe(url):\n",
        "    req = requests.get(url)\n",
        "    content = req.content\n",
        "    soup = bs(content, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "def get_today_date():\n",
        "    today = dt.date.today()\n",
        "    return today.strftime(\"%Y/%b/%d\")\n",
        "    #https://docs.python.org/2/library/datetime.html#strftime-strptime-behavior for strftime format explanation\n",
        "    \n",
        "def parse_link(soup):\n",
        "    todaynews = []\n",
        "    listlinks = soup.find_all(\"a\", {\"href\": True})\n",
        "    for link in listlinks:\n",
        "        if re.search(get_today_date(),link[\"href\"],re.I) != None:\n",
        "            todaynews.append(link[\"href\"])\n",
        "    return set(todaynews)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "bL98ezEjA0ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.theguardian.com/uk-news\"\n",
        "pagecontent = parsing_pipe(url)\n",
        "pagelist = parse_link(pagecontent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "BKPz2d-oA0w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_and_write_article(url, path):\n",
        "    pagesoup = parsing_pipe(url)\n",
        "    title = pagesoup.find(\"h1\").get_text()\n",
        "    #text = \" \".join([i.get_text() for i in pagesoup.find_all(\"p\")])\n",
        "    \n",
        "    with open(path + os.sep + url.rsplit(\"/\", 1)[1] + \".txt\", \"w+\", encoding = \"utf-8\") as f:\n",
        "        f.write(title + \"\\n\" + text)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "00v8cqYKA0w5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \".\" + os.sep + dt.date.today().strftime(\"%Y%m%d\")\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "except:\n",
        "    pass\n",
        "for link in pagelist:\n",
        "    pagesoup = parse_and_write_article(link, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "autoscroll": false,
        "ein.hycell": false,
        "ein.tags": "worksheet-0",
        "id": "BpMopXg6A0w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}